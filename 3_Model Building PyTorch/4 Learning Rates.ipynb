{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPai6lHaaTgTc5zuk0U02CG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#<font color='blue' size='5px'/> Learning Rates<font/>\n","\n","\n","\n"],"metadata":{"id":"kiuuArcFosDQ"}},{"cell_type":"markdown","source":["# 1 Introduction"],"metadata":{"id":"bMkTy_g0xG8n"}},{"cell_type":"markdown","source":["**Learning Rate** is a crucial hyperparameter in the training of machine learning models, including artificial neural networks. It determines the step size at which the model's parameters are updated during the optimization process. The learning rate influences how quickly or slowly a model converges to an optimal solution, and choosing the right learning rate is essential for successful model training.\n","\n","\n","<details>\n","  <summary>Importance of Learning Rate:</summary>\n","\n","- **Convergence:** A suitable learning rate helps the model converge to an optimal solution. If the learning rate is too high, the optimization process may overshoot the optimal point or oscillate. If it's too low, the process may converge very slowly or get stuck in local minima.\n","\n","- **Stability:** The learning rate affects the stability of the optimization process. A well-chosen learning rate leads to stable convergence, while a poorly chosen rate can lead to divergence or chaotic behavior.\n","\n","- **Generalization:** The learning rate can influence how well a model generalizes to unseen data. Overly aggressive learning rates may result in overfitting, while extremely small rates may lead to underfitting.\n","</details>\n","\n","\n","\n","\n","<details>\n","  <summary>Types of Learning Rate:</summary>\n","\n","1. **Fixed Learning Rate:** In this approach, the learning rate remains constant throughout the training process. It's simple and often works well when the dataset and model are well-behaved. However, it may lead to slow convergence and difficulty finding an optimal solution in more complex scenarios.\n","\n","2. **Learning Rate Annealing:** This technique involves gradually reducing the learning rate during training. Common annealing strategies include:\n","   - **Step Decay:** Reducing the learning rate at predefined intervals.\n","   - **Exponential Decay:** Reducing the learning rate exponentially over time.\n","   - **1/t Decay:** Reducing the learning rate as a function of the training iteration.\n","\n","   Learning rate annealing can help improve convergence and enable finer adjustments as the optimization process progresses.\n","\n","3. **Adaptive Learning Rate:** These methods dynamically adjust the learning rate based on the progress of optimization. Common adaptive learning rate algorithms include:\n","   - **Adagrad:** Adapts the learning rate for each parameter based on historical gradient information.\n","   - **RMSprop:** Adapts the learning rate with a moving average of squared gradients.\n","   - **Adam (Adaptive Moment Estimation):** Combines adaptive learning rate techniques with momentum.\n","\n","   Adaptive learning rates are highly effective in training deep neural networks and can speed up convergence significantly.\n","\n","4. **Cyclic Learning Rates:** These approaches involve cyclically increasing and decreasing the learning rate during training. The idea is to explore different learning rates to escape local minima and converge faster. Common methods include cyclic learning rate policies and the \"learning rate finder.\"\n","\n","5. **Warm-up Schedules:** In some cases, models are trained with a lower learning rate initially and gradually increase it. This \"warm-up\" phase helps stabilize training, particularly when using large learning rates.\n","\n","6. **Learning Rate Schedulers:** Learning rate schedulers adjust the learning rate based on specific criteria, such as the number of epochs or the validation loss. Popular schedulers include the StepLR, ReduceLROnPlateau, and CosineAnnealing schedulers.\n","\n","7. **One-cycle Learning Rates:** The one-cycle policy involves training with a learning rate that cyclically increases and decreases. It begins with a lower rate, increases to a maximum value, and then decreases again.\n","</details>\n","\n","\n","\n","<details>\n","  <summary>How to Choose the Right Learning Rate:</summary>\n","\n","Choosing the appropriate learning rate for your model and dataset often involves experimentation. Here's a general approach:\n","\n","1. Start with a moderate learning rate and observe the convergence behavior. If the loss is decreasing steadily, it may be a good choice.\n","\n","2. If the loss doesn't decrease or oscillates, try reducing the learning rate.\n","\n","3. If the model converges too slowly, try increasing the learning rate.\n","\n","4. Experiment with different learning rate schedules and adaptive techniques to fine-tune the training process.\n","\n","5. Cross-validation can help in selecting the best learning rate for your specific task.\n","\n","6. Learning rate ranges should be chosen wisely to perform a learning rate search. Techniques like the \"learning rate finder\" or random search can be useful for this purpose.\n","\n","The choice of learning rate is problem-specific, and the ideal rate can vary depending on factors such as the model architecture, dataset size, and complexity of the task. Therefore, a systematic approach to hyperparameter tuning, including learning rate, is essential for achieving the best model performance.\n","</details>"],"metadata":{"id":"GdWvG2RbxL-P"}},{"cell_type":"markdown","source":["# 2 Fixed Learning Rate"],"metadata":{"id":"j9spWXY3ye9C"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","**Fixed Learning Rate** is a straightforward learning rate strategy in the context of machine learning and deep learning. With a fixed learning rate, the learning rate remains constant throughout the training process. This means that the step size used to update the model parameters remains the same from the beginning to the end of training. Here's a detailed explanation of fixed learning rate and a numerical example:\n","\n","**Fixed Learning Rate Process:**\n","\n","1. **Initialization:** Choose a constant learning rate, typically denoted as $(\\alpha$), which is a small positive number. The learning rate is a hyperparameter that you must set before training your model. The choice of the learning rate can significantly impact the training process.\n","\n","2. **Training Loop:** During each training iteration (epoch or step), the model's parameters are updated using the fixed learning rate. The process typically involves the following steps:\n","\n","    a. **Forward Pass:** Use the current model parameters to make predictions on the training data.\n","\n","    b. **Loss Calculation:** Compute the loss, which quantifies the error between the model's predictions and the actual target values.\n","\n","    c. **Gradient Calculation:** Calculate the gradient of the loss with respect to the model parameters. The gradient points in the direction of the steepest ascent in the loss function.\n","\n","    d. **Parameter Update:** Adjust the model parameters (weights and biases) using the gradient and the fixed learning rate:\n","       \n","      $[ \\theta \\leftarrow \\theta - \\alpha \\nabla J(\\theta) $]\n","\n","      Here, $(\\theta$) represents the model's parameters, $(\\nabla J(\\theta)$) is the gradient, and $(\\alpha$) is the fixed learning rate.\n","\n","    e. **Iteration:** Repeat these steps for a predetermined number of iterations or until a convergence criterion is met. This process aims to minimize the loss and optimize the model's parameters.\n","\n","\n","\n","</details>"],"metadata":{"id":"JZ4uPGnYzYKI"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","Let's say we have a simple linear regression problem, where we want to predict the house prices based on their sizes. We have a dataset with the following data:\n","\n","| Size (in square feet) | Price (in thousands of dollars) |\n","|-----------------------|---------------------------------|\n","| 1000                  | 250                             |\n","| 1500                  | 350                             |\n","| 2000                  | 450                             |\n","| 2500                  | 550                             |\n","\n","- We want to use gradient descent to find the optimal parameters (slope and intercept) for our linear regression model. We initialize the parameters as follows:\n","\n","- Slope ($m$) = 0\n","- Intercept ($b$) = 0\n","\n","- We also choose a fixed learning rate of $\\alpha$ = 0.01.\n","\n","**We iterate through the following steps until convergence:**\n","\n","1. Calculate the predicted prices using the current parameters:\n","   - For the first data point (Size = 1000), the predicted price is:\n","     $$ \\text{predicted price} = m \\times \\text{Size} + b = 0 \\times 1000 + 0 = 0 $$\n","   - Similarly, we calculate the predicted prices for the other data points.\n","\n","2. Calculate the mean squared error (MSE) between the predicted prices and the actual prices:\n","   - For the first data point, the MSE is:\n","     $$ \\text{MSE} = \\frac{(\\text{predicted price} - \\text{actual price})^2}{2} = \\frac{(0 - 250)^2}{2} = 31250 $$\n","   - Similarly, we calculate the MSE for the other data points.\n","\n","3. Calculate the gradients of the parameters with respect to the MSE:\n","   - The gradient of the slope ($m$) is:\n","\n","     $$ \\frac{\\partial \\text{MSE}}{\\partial m} = \\frac{1}{4} \\sum_{i=1}^{4} (\\text{predicted price}_i - \\text{actual price}_i) \\times \\text{Size}_i = -3750 $$\n","\n","   - The gradient of the intercept ($b$) is:\n","   \n","     $$ \\frac{\\partial \\text{MSE}}{\\partial b} = \\frac{1}{4} \\sum_{i=1}^{4} (\\text{predicted price}_i - \\text{actual price}_i) = -250 $$\n","\n","4. Update the parameters using the gradients and the learning rate:\n","   - The new slope is:\n","     $$ m_{new} = m - \\alpha \\times \\frac{\\partial \\text{MSE}}{\\partial m} = 0 - 0.01 \\times (-3750) = 37.5 $$\n","   - The new intercept is:\n","     $$ b_{new} = b - \\alpha \\times \\frac{\\partial \\text{MSE}}{\\partial b} = 0 - 0.01 \\times (-250) = 2.5 $$\n","\n","5. Repeat steps 1-4 until convergence (i.e., until the MSE stops decreasing or reaches a minimum threshold).\n","\n","By using a fixed learning rate, we update our parameters by a fixed amount in each iteration, which can help us converge to an optimal solution faster. However, if we choose a learning rate that is too large, we risk overshooting the optimal solution and diverging from it instead. On the other hand, if we choose a learning rate that is too small, it may take longer for us to converge to an optimal solution.\n","\n","</details>"],"metadata":{"id":"o3dYTYGP-Zz1"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Code</summary>\n","\n","\n","Let's illustrate fixed learning rate with a simple numerical example using a basic linear regression problem. In this example, we aim to fit a straight line to a set of data points. We'll use a fixed learning rate to update the model's parameters during training.\n","\n","Suppose we have a dataset of points (x, y) and want to fit a linear model $(y = ax + b$) to the data. We'll use gradient descent with a fixed learning rate to find the values of $(a$) and $(b$) that minimize the mean squared error (MSE) loss.\n","\n","Here's a Python code example using a fixed learning rate:\n","\n","```python\n","import numpy as np\n","\n","# Generate synthetic data\n","np.random.seed(42)\n","X = np.random.rand(100, 1)\n","y = 3 * X + 2 + 0.1 * np.random.randn(100, 1)\n","\n","# Initialize model parameters\n","a = 1.0  # Initial guess for 'a'\n","b = 1.0  # Initial guess for 'b'\n","\n","# Fixed learning rate\n","learning_rate = 0.01\n","\n","# Number of training iterations\n","num_iterations = 1000\n","\n","# Training loop\n","for iteration in range(num_iterations):\n","    # Predicted values using the current model parameters\n","    y_pred = a * X + b\n","    \n","    # Calculate the mean squared error (MSE) loss\n","    mse_loss = ((y_pred - y)**2).mean()\n","    \n","    # Compute the gradients with respect to 'a' and 'b'\n","    grad_a = 2 * np.dot(X.T, (y_pred - y)) / X.shape[0]\n","    grad_b = 2 * (y_pred - y).mean()\n","    \n","    # Update model parameters using the fixed learning rate\n","    a -= learning_rate * grad_a\n","    b -= learning_rate * grad_b\n","    \n","    if (iteration + 1) % 100 == 0:\n","        print(f'Iteration {iteration + 1}, Loss: {mse_loss}, a: {a}, b: {b}')\n","```\n","\n","In this example:\n","\n","- We generate synthetic data points (X, y) for a linear regression task.\n","\n","- We initialize the model parameters 'a' and 'b' with arbitrary values.\n","\n","- We use a fixed learning rate of 0.01.\n","\n","- In each iteration, we calculate the loss, compute the gradients, and update the parameters 'a' and 'b' using the fixed learning rate.\n","\n","- The training loop repeats for a specified number of iterations, and we monitor the loss and parameter values.\n","\n","Fixed learning rates are simple to implement and can work well when you have prior knowledge of a suitable learning rate for your specific problem. However, in more complex scenarios, adaptive learning rate techniques are often preferred to achieve faster convergence and better results.\n","\n","</details>"],"metadata":{"id":"gpnTQWE5ze14"}},{"cell_type":"markdown","source":["# 3 Learning Rate Annealing"],"metadata":{"id":"FxhTilysygNA"}},{"cell_type":"markdown","source":["## Step Decay"],"metadata":{"id":"ngB5tnvY_-fd"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","**Learning Rate Annealing with Step Decay** is a technique used in training machine learning models, particularly neural networks, to adapt the learning rate during the training process.\n","- It involves **reducing the learning rate at specific predefined steps or epochs**.\n","- The goal is to **improve the convergence of the model by allowing for larger learning rates in the initial stages of training and then gradually reducing the learning rate as training progresses**. This can help the model converge more effectively and reach a better solution. Let's delve into the mathematics and usage of step decay learning rate annealing:\n","\n","**Mathematics of Step Decay:**\n","\n","1. **Initialization**: You start with an initial learning rate, denoted as \\(LR_0\\), which is typically set based on prior knowledge, experimentation, or hyperparameter tuning.\n","\n","2. **Annealing Schedule**: Define a schedule that specifies how the learning rate should change over time. In step decay, you reduce the learning rate by a fixed factor \\(\\gamma\\) at predefined intervals (steps or epochs). The new learning rate at each step is calculated as follows:\n","   \n","   $[LR_{\\text{new}} = \\gamma \\cdot LR_{\\text{old}}$]\n","\n","   Where:\n","   - $(LR_{\\text{new}}$) is the updated learning rate.\n","   - $(LR_{\\text{old}}$) is the current learning rate.\n","   - $(\\gamma$) is the decay factor, typically a value between 0 and 1.\n","\n","3. **Usage**:\n","   - Initially, the model uses the initial learning rate $(LR_0$) for training. This higher learning rate allows the model to make large parameter updates, which can speed up the initial stages of training.\n","   - At predefined intervals (e.g., every $(n$) epochs), you apply the annealing schedule and reduce the learning rate by the factor $(\\gamma$).\n","   - The process continues, with the learning rate decreasing at each step, until the training process is completed.\n","\n","**Benefits and Usage:**\n","\n","- **Faster Convergence**: Step decay helps the model converge faster in the initial stages, as the larger learning rate allows for more significant parameter updates.\n","\n","- **Stability**: As training progresses, reducing the learning rate can help stabilize the optimization process, preventing overshooting or oscillations in the loss landscape.\n","\n","- **Improved Generalization**: Gradually reducing the learning rate can help the model generalize better by fine-tuning its parameters as training proceeds.\n","\n","- **Robustness**: Step decay is a simple and effective technique that is widely used in practice for training deep neural networks, as it provides a balance between rapid convergence and stable optimization.\n","\n","- **Hyperparameter Tuning**: You can experiment with different decay factors and step intervals to find the values that work best for your specific problem.\n","\n","It's important to note that the choice of the decay factor (\\(\\gamma\\)) and the step size are hyperparameters that may require some experimentation to optimize for your specific problem. Different learning rate schedules, such as step decay, can be useful tools to enhance the training process and achieve better results in machine learning and deep learning tasks.\n","</details>"],"metadata":{"id":"qKSE77oIzk7P"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"gbY3Hkz-zk7Q"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","Here's a code example demonstrating step decay learning rate annealing during training with a PyTorch model for a linear regression problem:\n","\n","```python\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR\n","import numpy as np\n","\n","# Generate synthetic data\n","np.random.seed(42)\n","X = torch.rand(100, 1)\n","y = 3 * X + 2 + 0.1 * torch.randn(100, 1)\n","\n","# Define a simple linear regression model\n","class LinearRegression(nn.Module):\n","    def __init__(self):\n","        super(LinearRegression, self).__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","# Create the model\n","model = LinearRegression()\n","\n","# Define the loss function (mean squared error) and the optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# Learning rate schedule with step decay\n","def step_decay_schedule(initial_lr, decay_factor, step_size):\n","    def schedule(epoch):\n","        if (epoch + 1) % step_size == 0 and epoch > 0:\n","            return initial_lr * decay_factor\n","        return initial_lr\n","    return schedule\n","\n","# Set initial learning rate, decay factor, and step size\n","initial_lr = 0.1\n","decay_factor = 0.5\n","step_size = 10\n","\n","# Create a learning rate schedule\n","lr_schedule = StepLR(optimizer, step_size=step_size, gamma=decay_factor)\n","\n","# Training loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    # Adjust the learning rate according to the schedule\n","    lr_schedule.step()\n","    \n","    # Forward pass\n","    outputs = model(X)\n","    loss = criterion(outputs, y)\n","    \n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Learning Rate: {optimizer.param_groups[0][\"lr\"]}')\n","\n","# Check the final learned parameters (should be close to 3 and 2)\n","print('Learned parameters:', model.linear.weight.item(), model.linear.bias.item())\n","```\n","\n","In this PyTorch code example:\n","\n","- We generate synthetic data points (X, y) for a linear regression task.\n","\n","- We define a simple linear regression model using PyTorch's `nn.Module`.\n","\n","- We use the mean squared error (MSE) as the loss function and stochastic gradient descent (SGD) as the optimizer.\n","\n","- We define a step decay learning rate schedule using `StepLR` with a step size of 10 and a decay factor of 0.5. The learning rate will decrease by a factor of 0.5 every 10 epochs.\n","\n","- During the training loop, we adjust the learning rate according to the schedule using `lr_schedule.step()`.\n","\n","- The training process continues for a specified number of epochs, and we monitor the final learned parameters.\n","\n","Step decay learning rate annealing can help improve model convergence by allowing for larger learning rates initially and smaller learning rates as training progresses, which can be particularly useful in deep learning scenarios.\n","\n","</details>"],"metadata":{"id":"QqJUPBr-zk7Q"}},{"cell_type":"markdown","source":["## Exponential Decay"],"metadata":{"id":"cDs7YQNPAAMq"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","  \n","**Learning Rate Annealing with Exponential Decay** is a technique used in training machine learning models, particularly neural networks, to adapt the learning rate during the training process. It involves reducing the learning rate exponentially over time. This approach allows for a rapid reduction in the learning rate in the early stages of training and then slows down the rate of reduction as training progresses. Let's explore the mathematics and usage of exponential decay learning rate annealing:\n","\n","### Mathematics of Exponential Decay:\n","\n","1. **Initialization**: Start with an initial learning rate, denoted as \\(LR_0\\), which is typically set based on prior knowledge, experimentation, or hyperparameter tuning.\n","\n","2. **Annealing Schedule**: Define an exponential decay schedule that specifies how the learning rate should change over time. In exponential decay, the learning rate at each step or epoch is calculated as follows:\n","\n","   \\[LR_{\\text{new}} = LR_{\\text{old}} \\times \\gamma\\]\n","\n","   Where:\n","   - \\(LR_{\\text{new}}\\) is the updated learning rate.\n","   - \\(LR_{\\text{old}}\\) is the current learning rate.\n","   - \\(\\gamma\\) is the decay factor, which is typically a value between 0 and 1.\n","\n","3. **Usage**:\n","   - Initially, the model uses the initial learning rate \\(LR_0\\) for training. This higher learning rate allows the model to make large parameter updates, which can speed up the initial stages of training.\n","   - At each step or epoch, you apply the annealing schedule, reducing the learning rate by the factor \\(\\gamma\\).\n","   - The process continues, with the learning rate decreasing exponentially at each step, until the training process is completed.\n","\n","### Benefits and Usage:\n","\n","- **Rapid Early Convergence**: Exponential decay allows for a swift reduction in the learning rate in the early stages of training, enabling the model to converge quickly to a reasonable solution.\n","\n","- **Fine-Tuning**: As training progresses, the learning rate reduction rate slows down, which is useful for fine-tuning the model's parameters.\n","\n","- **Stability**: The gradual reduction of the learning rate can help stabilize the optimization process and prevent overshooting or oscillations in the loss landscape.\n","\n","- **Generalization**: Exponential decay can contribute to better generalization, as it allows the model to adapt its parameters more carefully as training proceeds.\n","\n","- **Hyperparameter Tuning**: You can experiment with different decay factors (\\(\\gamma\\)) to find the values that work best for your specific problem.\n","\n","Exponential decay learning rate annealing is a powerful tool for training deep neural networks and is widely used in practice. It provides a balance between rapid early convergence and fine-tuning the model for better generalization. By adjusting the decay factor and the initial learning rate, you can tailor this technique to your specific problem and achieve improved training outcomes.\n","\n","</details>"],"metadata":{"id":"OtcetSRDAkAL"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"q0au1MXEAkAX"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","Certainly! Here's a PyTorch code example demonstrating exponential decay learning rate annealing during the training of a simple linear regression model:\n","\n","```python\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ExponentialLR\n","import numpy as np\n","\n","# Generate synthetic data\n","np.random.seed(42)\n","X = torch.rand(100, 1)\n","y = 3 * X + 2 + 0.1 * torch.randn(100, 1)\n","\n","# Define a simple linear regression model\n","class LinearRegression(nn.Module):\n","    def __init__(self):\n","        super(LinearRegression, self).__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","# Create the model\n","model = LinearRegression()\n","\n","# Define the loss function (mean squared error) and the optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# Exponential decay learning rate schedule\n","def exponential_decay_schedule(initial_lr, gamma):\n","    scheduler = ExponentialLR(optimizer, gamma=gamma)\n","    return scheduler\n","\n","# Set initial learning rate and decay factor\n","initial_lr = 0.1\n","decay_factor = 0.9\n","\n","# Create the learning rate scheduler\n","lr_scheduler = exponential_decay_schedule(initial_lr, gamma=decay_factor)\n","\n","# Training loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    # Adjust the learning rate according to the schedule\n","    lr_scheduler.step()\n","    \n","    # Forward pass\n","    outputs = model(X)\n","    loss = criterion(outputs, y)\n","    \n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Learning Rate: {optimizer.param_groups[0][\"lr\"]}')\n","\n","# Check the final learned parameters (should be close to 3 and 2)\n","print('Learned parameters:', model.linear.weight.item(), model.linear.bias.item())\n","```\n","\n","In this PyTorch code example:\n","\n","- We generate synthetic data points (X, y) for a linear regression task.\n","\n","- We define a simple linear regression model using PyTorch's `nn.Module`.\n","\n","- We use the mean squared error (MSE) as the loss function and stochastic gradient descent (SGD) as the optimizer.\n","\n","- We implement exponential decay learning rate annealing using the `ExponentialLR` scheduler.\n","\n","- The learning rate is reduced by a factor of 0.9 at each epoch, following the exponential decay schedule.\n","\n","- The training process continues for a specified number of epochs, and we monitor the final learned parameters.\n","\n","Exponential decay learning rate annealing helps the model to converge rapidly in the early stages and fine-tune its parameters as training progresses. It's a useful technique in various machine learning and deep learning tasks.\n","\n","</details>"],"metadata":{"id":"fhwdYLqrAkAX"}},{"cell_type":"markdown","source":["## 1/t Decay"],"metadata":{"id":"Fv7702ujAGR0"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","**Learning Rate Annealing with 1/t Decay** is a technique used in training machine learning models, particularly neural networks, to adjust the learning rate during training. This approach decreases the learning rate over time, following an inverse time (1/t) decay schedule. It allows for a slower reduction in the learning rate, which can be beneficial for fine-tuning the model as training progresses. Let's explore the mathematics and usage of 1/t decay learning rate annealing:\n","\n","### Mathematics of 1/t Decay:\n","\n","1. **Initialization**: Start with an initial learning rate, denoted as \\(LR_0\\), typically chosen based on prior knowledge, experimentation, or hyperparameter tuning.\n","\n","2. **Annealing Schedule**: Define a 1/t decay schedule that specifies how the learning rate should change over time. In 1/t decay, the learning rate at each step or epoch is calculated as follows:\n","\n","   \\[LR_{\\text{new}} = \\frac{LR_0}{1 + \\alpha \\cdot t}\\]\n","\n","   Where:\n","   - \\(LR_{\\text{new}}\\) is the updated learning rate.\n","   - \\(LR_0\\) is the initial learning rate.\n","   - \\(\\alpha\\) is a hyperparameter that controls the rate of decay.\n","   - \\(t\\) is the current training step or epoch.\n","\n","3. **Usage**:\n","   - Initially, the model uses the initial learning rate \\(LR_0\\) for training. This higher learning rate allows the model to make large parameter updates, which can speed up the initial stages of training.\n","   - As training progresses, the learning rate decreases slowly following the 1/t decay schedule. The learning rate continues to decrease over time, allowing the model to fine-tune its parameters.\n","\n","### Benefits and Usage:\n","\n","- **Fine-Tuning**: 1/t decay provides a slow and gradual reduction in the learning rate, which can be beneficial for fine-tuning the model's parameters as training progresses.\n","\n","- **Stability**: The gradual reduction in the learning rate can help stabilize the optimization process and prevent overshooting or oscillations in the loss landscape.\n","\n","- **Generalization**: Slower learning rate decay can contribute to better generalization, as it allows the model to adapt its parameters more carefully as training proceeds.\n","\n","- **Hyperparameter Tuning**: You can experiment with different values of the hyperparameter \\(\\alpha\\) to control the decay rate and find the values that work best for your specific problem.\n","\n","1/t decay learning rate annealing is a valuable tool for training deep neural networks. It balances rapid initial convergence and fine-tuning for better generalization. By adjusting the hyperparameter \\(\\alpha\\) and the initial learning rate, you can customize this technique to your specific problem and achieve improved training results.\n","\n","</details>"],"metadata":{"id":"gA2jv-03Ak2T"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"qftSu0rZAk2g"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","Certainly! Here's a PyTorch code example demonstrating 1/t decay learning rate annealing during the training of a simple linear regression model:\n","\n","```python\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","# Generate synthetic data\n","np.random.seed(42)\n","X = torch.rand(100, 1)\n","y = 3 * X + 2 + 0.1 * torch.randn(100, 1)\n","\n","# Define a simple linear regression model\n","class LinearRegression(nn.Module):\n","    def __init__(self):\n","        super(LinearRegression, self).__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","# Create the model\n","model = LinearRegression()\n","\n","# Define the loss function (mean squared error) and the optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# 1/t decay learning rate schedule\n","def one_over_t_decay_schedule(initial_lr, alpha, t):\n","    return initial_lr / (1 + alpha * t)\n","\n","# Set initial learning rate and hyperparameter alpha\n","initial_lr = 0.1\n","alpha = 0.01\n","\n","# Training loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    # Adjust the learning rate according to the schedule\n","    current_lr = one_over_t_decay_schedule(initial_lr, alpha, epoch)\n","    \n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = current_lr\n","    \n","    # Forward pass\n","    outputs = model(X)\n","    loss = criterion(outputs, y)\n","    \n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Learning Rate: {current_lr}')\n","\n","# Check the final learned parameters (should be close to 3 and 2)\n","print('Learned parameters:', model.linear.weight.item(), model.linear.bias.item())\n","```\n","\n","In this PyTorch code example:\n","\n","- We generate synthetic data points (X, y) for a linear regression task.\n","\n","- We define a simple linear regression model using PyTorch's `nn.Module`.\n","\n","- We use the mean squared error (MSE) as the loss function and stochastic gradient descent (SGD) as the optimizer.\n","\n","- We implement 1/t decay learning rate annealing using a custom function `one_over_t_decay_schedule`. The learning rate decreases over time according to the 1/t decay schedule.\n","\n","- During the training loop, we adjust the learning rate for each epoch using the calculated value from the 1/t decay schedule.\n","\n","- The training process continues for a specified number of epochs, and we monitor the final learned parameters.\n","\n","1/t decay learning rate annealing provides a slow and gradual reduction in the learning rate, which can be beneficial for fine-tuning the model's parameters as training progresses. This technique is useful in various machine learning and deep learning tasks.\n","</details>"],"metadata":{"id":"gZYuYJoKAk2g"}},{"cell_type":"markdown","source":["# 4 Adaptive Learning Rate"],"metadata":{"id":"23IOYNy8yjtx"}},{"cell_type":"markdown","source":["## Adagrad"],"metadata":{"id":"0qqkTSxFCbOt"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"Wqdw4RFyzlXP"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"eOYBc9KizlXP"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"SvZxF9FrzlXQ"}},{"cell_type":"markdown","source":["## RMSprop"],"metadata":{"id":"8pZCxMPVCdUz"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"CwgtYvJdCh53"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"IcD_b5QxCh6B"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"gpw9xkqfCh6C"}},{"cell_type":"markdown","source":["## Adam (Adaptive Moment Estimation)"],"metadata":{"id":"o0j5r3HICfg8"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"G9LTlUbHCin7"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"Ni8qH4PjCin8"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"IQ1kaoriCin8"}},{"cell_type":"markdown","source":["# 5 Cyclic Learning Rates"],"metadata":{"id":"IUgdk8_ayobS"}},{"cell_type":"markdown","source":["## Cyclic learning rate policies\n","\n"],"metadata":{"id":"97V2AU7hCr8z"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"WkL4RhHCzlta"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"mnPC4cFkzlta"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"vIasZ9Gkzlta"}},{"cell_type":"markdown","source":["## learning rate finder"],"metadata":{"id":"eP_g1om_CxOS"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"0Rnl3-V5C1Ff"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"PknjwzW9C1F9"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"ORvD5uADC1F_"}},{"cell_type":"markdown","source":["# 6 Warm-up Schedules"],"metadata":{"id":"Iu9i8q3bytqQ"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"ER7eFYi4zmGg"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"pS4YmsGJzmGg"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"t-pW_JtdzmGh"}},{"cell_type":"markdown","source":["# 7 Learning Rate Schedulers"],"metadata":{"id":"t9biYR3Nyti9"}},{"cell_type":"markdown","source":["## StepLR"],"metadata":{"id":"FrnDYEHqDzOs"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"lLi69Ut9zmkQ"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"YLFywRkxzmkR"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"dIGJ-_6JzmkR"}},{"cell_type":"markdown","source":["## ReduceLROnPlateau"],"metadata":{"id":"eit8wGSbD1xr"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"cn0sfk4pEBTE"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"F4drvUu-EBTP"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"LLvHvNAYEBTP"}},{"cell_type":"markdown","source":["## CosineAnnealing schedulers"],"metadata":{"id":"IsGmOA5JD9SM"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"ZL-P3eyWECMU"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"YWp9-fdEECMV"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"VQczkcxIECMV"}},{"cell_type":"markdown","source":["# 8 One-cycle Learning Rates"],"metadata":{"id":"NgWAs0_3y29L"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Theory</summary>\n","\n","</details>"],"metadata":{"id":"8-JfxWi4znAn"}},{"cell_type":"markdown","source":["<details>\n","  <summary>Numerical Example</summary>\n","\n","</details>"],"metadata":{"id":"U6pvzAAZznAo"}},{"cell_type":"markdown","source":["<details>\n","  <summary>code</summary>\n","\n","</details>"],"metadata":{"id":"_8uM82mOznAo"}}]}